{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import Packages\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "from PIL import Image\r\n",
        "import cv2\r\n",
        "\r\n",
        "import matplotlib.pyplot as plot\r\n",
        "import matplotlib.patches as patches\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "from tensorflow.keras import layers\r\n",
        "import h5py"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1615216381849
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mask Detection Function\r\n",
        "def MaskDetectionVideo(img,classifier=cv2.CascadeClassifier(\"../Data/processed/classifier.xml\"),model=keras.models.load_model(\"../Data/processed/model.h5\"),sf=1.1,mn=1):\r\n",
        "    #gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\r\n",
        "    detections = classifier.detectMultiScale(img,scaleFactor=sf,minNeighbors=mn)\r\n",
        "    for detection in detections:\r\n",
        "        xmin = int(detection[0])\r\n",
        "        ymin = int(detection[1])\r\n",
        "        width = int(detection[2])\r\n",
        "        height = int(detection[3])\r\n",
        "        xmax = xmin+width\r\n",
        "        ymax = ymin+height\r\n",
        "        face = img[ymin:ymax, xmin:xmax]\r\n",
        "        resized = cv2.resize(face,(32,32))\r\n",
        "        scaledInput = resized/255.0\r\n",
        "        test = np.stack([scaledInput])\r\n",
        "        prediction = model.predict_classes(test)\r\n",
        "        color = [0,0,255] if prediction[0][0]==0 else [255,0,0]\r\n",
        "        return cv2.rectangle(frame,(xmin,ymin),(xmax,ymax),color,2)\r\n",
        "    "
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1615216505030
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Video model prediction\r\n",
        "# Not currently working (Likely due to video inability to capture video within Azure ML)\r\n",
        "vid = cv2.VideoCapture(0) \r\n",
        "model=keras.models.load_model(\"../Data/processed/model.h5\")\r\n",
        "classifier=cv2.CascadeClassifier(\"../Data/processed/classifier.xml\")  \r\n",
        "while(True): \r\n",
        "    ret, frame = vid.read() \r\n",
        "    classified = MaskDetectionVideo(frame,classifier,model)\r\n",
        "    cv2.imshow('frame', classified) \r\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'): \r\n",
        "        break\r\n",
        "vid.release() \r\n",
        "cv2.destroyAllWindows() "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}